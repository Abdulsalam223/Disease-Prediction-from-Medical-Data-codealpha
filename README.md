# Disease Prediction from Medical Data

A comprehensive machine learning project that predicts the possibility of diseases based on patient data using multiple classification algorithms. This project analyzes three different medical datasets and compares the performance of various ML models.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Datasets](#datasets)
- [Models Implemented](#models-implemented)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Results](#results)
- [Visualizations](#visualizations)
- [Key Findings](#key-findings)
- [Usage](#usage)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project applies classification techniques to structured medical datasets to predict disease occurrence. The implementation includes comprehensive exploratory data analysis, feature engineering, model training, and detailed performance evaluation across three different medical conditions.

### Objective
Predict the possibility of diseases based on patient data using machine learning classification algorithms.

### Approach
- Apply multiple classification algorithms to medical datasets
- Compare model performance using various metrics
- Perform detailed feature importance analysis
- Provide comprehensive visualizations for model evaluation

## âœ¨ Features

- **Multi-Dataset Analysis**: Evaluation across three different disease datasets
- **Multiple ML Algorithms**: Implementation of 4 different classification models
- **Comprehensive Metrics**: Accuracy, Precision, Recall, F1-Score, and ROC-AUC
- **Cross-Validation**: 5-fold CV for robust performance estimation
- **Feature Importance Analysis**: Identification of key predictive factors
- **Rich Visualizations**: 
  - Target distribution plots
  - Correlation heatmaps
  - Model comparison charts
  - Confusion matrices
  - ROC curves
  - Feature importance plots

## ğŸ“Š Datasets

### 1. Heart Disease Dataset
- **Source**: UCI Machine Learning Repository
- **Features**: Age, sex, chest pain type, blood pressure, cholesterol, ECG results, etc.
- **Target**: Presence or absence of heart disease

### 2. Diabetes Dataset
- **Source**: Pima Indians Diabetes Database
- **Features**: Pregnancies, glucose, blood pressure, insulin, BMI, age, etc.
- **Target**: Diabetes outcome (0 or 1)

### 3. Breast Cancer Dataset
- **Source**: Wisconsin Breast Cancer Dataset
- **Features**: Radius, texture, perimeter, area, smoothness, compactness, etc.
- **Target**: Diagnosis (Malignant or Benign)

## ğŸ¤– Models Implemented

1. **Logistic Regression**
   - Linear classification model
   - Baseline performance benchmark
   - Interpretable coefficients

2. **Support Vector Machine (SVM)**
   - Non-linear decision boundaries
   - Kernel-based classification
   - Probability estimates enabled

3. **Random Forest**
   - Ensemble of decision trees
   - Feature importance extraction
   - Robust to overfitting

4. **XGBoost**
   - Gradient boosting framework
   - State-of-the-art performance
   - Efficient handling of imbalanced data

## ğŸ› ï¸ Installation

### Prerequisites
```bash
Python 3.7+
```

### Required Libraries
```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost
```

### Detailed Dependencies
```python
numpy>=1.19.0
pandas>=1.1.0
matplotlib>=3.3.0
seaborn>=0.11.0
scikit-learn>=0.24.0
xgboost>=1.4.0
```

## ğŸ“ Project Structure

```
disease-prediction/
â”‚
â”œâ”€â”€ notebook.ipynb              # Main Jupyter notebook
â”œâ”€â”€ README.md                   # Project documentation
â”‚
â”œâ”€â”€ data/                       # Dataset directory
â”‚   â”œâ”€â”€ heart.csv
â”‚   â”œâ”€â”€ diabetes.csv
â”‚   â””â”€â”€ breast_cancer.csv
â”‚
â”œâ”€â”€ visualizations/             # Generated plots
â”‚   â”œâ”€â”€ target_distributions/
â”‚   â”œâ”€â”€ correlation_heatmaps/
â”‚   â”œâ”€â”€ model_comparisons/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â”œâ”€â”€ roc_curves/
â”‚   â””â”€â”€ feature_importance/
â”‚
â””â”€â”€ models/                     # Saved trained models
    â”œâ”€â”€ heart_disease/
    â”œâ”€â”€ diabetes/
    â””â”€â”€ breast_cancer/
```

## ğŸ“ˆ Results

### Performance Summary

| Dataset | Best Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|---------|-----------|----------|-----------|--------|----------|---------|
| **Heart Disease** | Random Forest | 100.00% | 100.00% | 100.00% | 100.00% | 100.00% |
| **Diabetes** | SVM | 75.32% | 66.00% | 61.11% | 63.46% | 79.24% |
| **Breast Cancer** | XGBoost | 97.37% | 100.00% | 92.86% | 96.30% | 99.50% |

### Detailed Model Performance

#### Heart Disease Dataset
| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC | CV Score |
|-------|----------|-----------|--------|----------|---------|----------|
| Logistic Regression | 80.98% | 76.19% | 91.43% | 83.12% | 92.98% | 84.39% Â± 2.40% |
| SVM | 92.68% | 91.67% | 94.29% | 92.96% | 97.71% | 91.22% Â± 1.95% |
| **Random Forest** | **100.00%** | **100.00%** | **100.00%** | **100.00%** | **100.00%** | **98.17% Â± 1.64%** |
| XGBoost | 100.00% | 100.00% | 100.00% | 100.00% | 100.00% | 98.66% Â± 1.05% |

#### Diabetes Dataset
| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC | CV Score |
|-------|----------|-----------|--------|----------|---------|----------|
| Logistic Regression | 71.43% | 60.87% | 51.85% | 56.00% | 82.30% | 77.85% Â± 1.26% |
| **SVM** | **75.32%** | **66.00%** | **61.11%** | **63.46%** | **79.24%** | **75.41% Â± 1.66%** |
| Random Forest | 75.97% | 68.09% | 59.26% | 63.37% | 81.47% | 76.39% Â± 3.14% |
| XGBoost | 73.38% | 62.26% | 61.11% | 61.68% | 80.52% | 72.64% Â± 3.70% |

#### Breast Cancer Dataset
| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC | CV Score |
|-------|----------|-----------|--------|----------|---------|----------|
| Logistic Regression | 96.49% | 97.50% | 92.86% | 95.12% | 99.60% | 97.14% Â± 1.12% |
| SVM | 96.49% | 97.50% | 92.86% | 95.12% | 99.47% | 97.36% Â± 1.49% |
| Random Forest | 95.61% | 100.00% | 88.10% | 93.67% | 99.17% | 95.60% Â± 3.48% |
| **XGBoost** | **97.37%** | **100.00%** | **92.86%** | **96.30%** | **99.50%** | **96.48% Â± 2.13%** |

## ğŸ“Š Visualizations

### 1. Target Distribution Analysis
- Class balance visualization for each dataset
- Bar plots and pie charts showing distribution
- Imbalance ratio calculations

### 2. Correlation Heatmaps
- Feature correlation analysis
- Identification of multicollinearity
- Feature relationship insights

### 3. Model Comparison Charts
- Side-by-side metric comparisons
- Overall performance visualization
- Easy identification of best models

### 4. Confusion Matrices
- True/False positive/negative analysis
- Model prediction accuracy breakdown
- Error pattern identification

### 5. ROC Curves
- AUC comparison across models
- Threshold selection insights
- Model discrimination ability

### 6. Feature Importance
- Top predictive features for each disease
- Tree-based model feature rankings
- Clinical relevance insights

## ğŸ” Key Findings

### Heart Disease
- **Best Models**: Random Forest and XGBoost achieved perfect scores on test data
- **Key Features**: Chest pain type, exercise-induced angina, ST depression
- **Insight**: Tree-based models excel at capturing complex interactions in cardiac data
- **Note**: Perfect scores may indicate potential overfitting; validation on external data recommended

### Diabetes
- **Best Model**: SVM with 75.32% accuracy
- **Challenge**: Most difficult dataset with moderate performance across all models
- **Key Features**: Glucose levels, BMI, age, insulin levels
- **Insight**: Class imbalance and feature overlap make this a challenging prediction task

### Breast Cancer
- **Best Model**: XGBoost with 97.37% accuracy and 100% precision
- **Key Features**: Cell nucleus characteristics (radius, texture, concavity)
- **Insight**: High-quality features lead to excellent model performance
- **Clinical Value**: High precision critical for cancer diagnosis

### Cross-Dataset Insights
1. **Model Selection**: No single model dominates across all datasets
2. **Dataset Quality**: Feature engineering and data quality significantly impact performance
3. **Ensemble Methods**: Random Forest and XGBoost consistently perform well
4. **Trade-offs**: Balance between precision and recall varies by disease context

## ğŸ’» Usage

### Running the Complete Analysis

```python
# 1. Load and prepare data
# 2. Perform EDA
# 3. Train models
# 4. Evaluate performance
# 5. Generate visualizations

# Simply run all cells in the Jupyter notebook sequentially
```

### Training Individual Models

```python
# Example: Train XGBoost on Heart Disease data
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import xgboost as xgb

# Prepare data
X_train, X_test, y_train, y_test = train_test_split(
    X_heart, y_heart, test_size=0.2, random_state=42, stratify=y_heart
)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train model
model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)
model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)
```

### Making Predictions on New Data

```python
# Example prediction
new_patient = [[63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]]
new_patient_scaled = scaler.transform(new_patient)
prediction = model.predict(new_patient_scaled)
probability = model.predict_proba(new_patient_scaled)

print(f"Prediction: {'Disease' if prediction[0] == 1 else 'No Disease'}")
print(f"Confidence: {probability[0][prediction[0]]:.2%}")
```

## ğŸš€ Future Improvements

### Model Enhancements
- [ ] Hyperparameter tuning using GridSearchCV or RandomizedSearchCV
- [ ] Implement ensemble methods (Voting, Stacking)
- [ ] Deep learning approaches (Neural Networks)
- [ ] AutoML frameworks for automated optimization

### Data Improvements
- [ ] Collect more training samples
- [ ] Feature engineering and selection
- [ ] Handle class imbalance with SMOTE/ADASYN
- [ ] External dataset validation

### Deployment
- [ ] Create REST API for model serving
- [ ] Build web interface for predictions
- [ ] Docker containerization
- [ ] Cloud deployment (AWS/GCP/Azure)

### Additional Analysis
- [ ] SHAP values for model interpretability
- [ ] Calibration curves analysis
- [ ] Cost-sensitive learning
- [ ] Multi-model ensemble predictions

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¥ Authors

- **Your Name** - *Initial work*

## ğŸ™ Acknowledgments

- UCI Machine Learning Repository for providing the datasets
- scikit-learn and XGBoost development teams
- Medical research community for domain insights

## ğŸ“§ Contact

For questions or feedback, please reach out:
- Email: your.email@example.com
- LinkedIn: www.linkedin.com/in/abdulsalam001
- GitHub: [@abdulsalam223](https://github.com/abdulsalam223)

## ğŸ“š References

1. UCI Machine Learning Repository - Heart Disease Dataset
2. Pima Indians Diabetes Database
3. Wisconsin Breast Cancer Dataset
4. scikit-learn Documentation
5. XGBoost Documentation

---

**Note**: This project is for educational and research purposes. Models should not be used for actual medical diagnosis without proper validation, regulatory approval, and oversight by medical professionals.
